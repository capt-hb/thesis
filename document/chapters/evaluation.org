* Evaluation
  <<sec:evaluation>>
  Two kinds of evaluation were performed, the first one being the unit testing of instructions,
  for the modified and new instructions. The second evaluation is concerned with the new calling
  convention and how it compares to the calling convention currently in use on CHERI-MIPS.
  
  For both evaluations the same testing infrastructure is used. The tests are added to a fork of the
  cheritest[fn:cheritest] repository. The cheritest repository[fn:cheritest-original], developed by 
  the researchers behind CHERI, makes it easy to run tests on the CHERI-MIPS simulator. Tests are
  defined by an assembly file and python file (both must have the same name, only the file extension
  should differ). The python file is used to make the test assertions
  based on the log file produced by running the machine code (compiled from the assembly file) on
  the CHERI-MIPS simulator. The log file contains the contents of the registers (both the 
  general-purpose registers and the capability registers), how many instructions were executed,
  the time elapsed for running the instructions (in nanoseconds), how many instructions were executed
  per second and some other information that is of less relevance for the evaluation.
  
  The following sections will mention where the tests can be found, this is for the fork of the 
  cheritest repository[fn:cheritest]. The tests are run on the C simulator of CHERI-MIPS, as 
  generated by Sail.

[fn:cheritest]https://github.com/capt-hb/cheritest
[fn:cheritest-original]Original cheritest repository: https://github.com/CTSRD-CHERI/cheritest

** Unit Testing Instructions
   The unit tests for the modified and new instructions can be found in  \\
   ~tests/uninitialized_capabilities~.
   These tests are focused on the behavior of the instructions and they all pass.
   I will not go over each test individually, this would become rather tedious to read, a small
   description of each test file can be found in Table \ref{tab:unit-tests-description}.
   
   #+NAME: tab:unit-tests-description
   #+CAPTION: Unit tests with small description
   | Test File                    | Description                                                 |
   |------------------------------+-------------------------------------------------------------|
   | ~test_cshrink~               | Test that the bounds of a capability are correctly updated  |
   | ~test_cdropuninit~           | Test that only an uninitialized capability with cursor=base |
   |                              | can drop the uninit permission                              |
   | ~test_csealuninit~           | Test that a sealed capability can't be mutated by trying to |
   |                              | make it uninit                                              |
   | ~test_uninit~                | Test that the cuninit instruction makes a capability        |
   |                              | uninitialized                                               |
   | ~test_uninit_cap_csetaddr~   | Test that the address of an uninitialized capability        |
   |                              | cannot be lowered                                           |
   | ~test_uninit_cap_offset~     | Test that offsets are updated correctly and that offset     |
   |                              | cannot be lowered                                           |
   | ~test_uninit_cap_ucstore~    | Test that the UCS[BHWD] works as expected                   |
   | ~test_uninit_cap_ucstorecap~ | Similar to ~test_uninit_cap_ucstore~                        |
   
   I will discuss one test in more detail, ~test_cshrink~, to give the reader of the thesis a better
   understanding of how these are written. This will make it easier to inspect the test files
   yourself and will come in handy for the second evaluation. 
   
   The ~test_cshrink~ test exists of two files, the assembly file containing the instructions to be
   run on the machine (~test_cshrink.s~) and a python file (~test_cshrink.py~)to make assertions 
   on the log file produced by the simulator.
   
   The assembly file exists of two parts, one part is the test instructions to be executed,
   wrapped in the ~BEGIN_TEST~ and ~END_TEST~ macros and the second part is data part, which
   will be used to create a capability for and write to/read from. The data part defines a
   few words and is further not important to understand the test. I will focus on the first part,
   the test instructions:
   #+begin_src cherimips -n
   cgetdefault $c1
   dla $t0, data
   csetoffset $c1, $c1, $t0
   csetboundsimm $c1, $c1, 10
   cincoffsetimm $c1, $c1, 8
   cgetbase $t0, $c1

   cshrink $c2, $c1, 0 # length of $c2 = offset = 8
   dli $s0, 10
   ucsb $c2, $s0, -1($c2)
   cgetlen $a0, $c1
   cgetlen $a1, $c2
   cgetbase $t3, $c2

   csetoffset $c1, $c1, $a0
   cincoffset $c1, $c1, 1
   cshrink $c3, $c1, 0 # error: shrinking with offset out of bounds shouldn't work

   cincoffset $c4, $c1, -10
   cshrink $c4, $c4, $t0
   cgetbase $t1, $c4
   cgetlen $a2, $c4

   cincoffset $c5, $c1, -1 # cursor will now be on end 
   cshrink $c5, $c5, 0
   cgetlen $a3, $c5
   cshrink $c6, $c5, 1
   cgetbase $t2, $c6
   ucsb $c5, $s0, -1($c5)
   #+end_src
   
   Lines 1-6 setup the capability and store the base of /$c1/ into /$t0/. Next, a cshrink instruction
   is issued to shrink the capability /$c1/ to a capability with the same base but with as end the
   current cursor of /$c1/. A store instruction follows, to make sure no error is thrown after
   shrinking a capability. Then some values of /$c1/ and /$c2/ are stored in registers /$a0/, /$a1/
   and /$t3/.
   On lines 15-17, the cursor of the capability is set to the end of the capability and right after
   that is incremented by one. This means that the cursor is now out of bounds ($cursor > end$) and
   shrinking the capability should raise an error.
   The remaining instructions are similar to those discussed earlier.
   
   It is now clear what the assembly test instructions do. What remains to be explained is the
   test cases written in the python file:
   #+begin_src python -n
   from beritest_tools import BaseBERITestCase

   class test_cshrink(BaseBERITestCase):
      EXPECTED_EXCEPTIONS = 1

      def test_cshrink_lowers_end(self):
         '''Test that lowering the end of a capability works'''
         assert self.MIPS.a0 == 10
         assert self.MIPS.a1 == 8
         assert self.MIPS.a1 < self.MIPS.a0
         assert self.MIPS.a2 == 1

      def test_cshrink_with_cursor_at_end_does_nothing(self):
         '''Test that using cshrink with a capability for which cursor=end does not change end'''
         assert self.MIPS.a0 == self.MIPS.a3

      def test_cshrink_increases_base(self):
         assert self.MIPS.t0 == self.MIPS.t1
         assert self.MIPS.t0 == self.MIPS.t3
         assert self.MIPS.t0 + 1 == self.MIPS.t2
   #+end_src

   The test class needs to be the same name as the file (~test_cshrink~) and subclasses \\
   ~BaseBERITestCase~ (which gives it easy access to the contents of the log file for this
   test). The ~EXPECTED_EXCEPTIONS~ is declared to be one (the error that is expected as explained
   in the assembly file discussion). Three methods are defined, the first methods, 
   ~test_cshrink_lowers_end~ tests that the cshrink instruction correctly lowers the end
   of a capability. Here you can see why subclassing ~BaseBERITestCase~ is useful, the registers
   can be addressed as ~self.MIPS.a0~. The second method, ~test_cshrink_with_cursor_at_end_does_nothing~
   tests that shrinking a capability (in which we don't change the base of the capability) with its
   cursor already at the end does not change the end of the capability. The last method,
   ~test_cshrink_increases_base~ is similar to ~test_cshrink_lowers_end~.

** Calling Convention 
   To evaluate the calling convention, pairs of tests were used. The pair consists of a test for
   the original calling convention and a test for the new calling convention. These pairs were
   created for a few example programs. 
   In this section I will go over the different programs used to test the new calling convention
   and what the results are. The results entail the semantics preservation of the calling convention
   (using the original and new calling convention produces the same output), how many instructions
   each assembly file required (remember that a test consists of a python file and an assembly file,
   and because I use a pair of tests there is an assembly file for each calling convention) and the
   execution time of the assembly code on the C simulator of CHERI-MIPS.
   As in the previous section, the complete test files can be found in the cheritest[fn:cheritest]
   repository, but this time in the /tests/purecap/ directory. These tests were written in the
   purecap directory so that they are executed using the pure capability calling convention.
   The assembly files are based on the output by running the following command:
   #+begin_src bash
   clang -S <source_file> -mcpu=beri -mabi=purecap -cheri-linker -cheri=256 \
         -target cheri-unknown-freebsd -Wall -fomit-frame-pointer -O0 <output_file>
   #+end_src
   The output file generated by this command is not sufficient to be used as a purecap test,
   the ~main~ routine needs to be renamed to ~test~. The adjusted assembly file can then be
   used for the /original/ test of the pair. A manual modification of this files was performed
   to have it use the secure calling convention as described in Section [[sec:secure-cc]].
   
   First, some general results are given concerning the number of instruction of the prologue
   and epilogue of functions. Then the evaluation continues by going over the considered programs
   and giving the results of the evaluation of that program. The performance of the assembly code
   is measured in nanoseconds (the Y-axis on the boxplots) and is repeated 20 times. When the 
   performance is shown in tables or text it will be shown in microseconds for readability.
   
   Each test discussed in the upcoming sections consists of four files, two files for the original
   calling convention and two for the secure (also referred to as /uninit/) calling convention. 
   The two files per calling convention are the assembly file (/.s/ file extension) and the python 
   file (/.py/ file extension). The tests can be found in the purecap directory with their full 
   name shown in Table \ref{tab:test-files}, note that ~<calling-convention>~ is ~original~ or 
   ~uninit~.

    #+CAPTION: Test files for each test
    #+NAME: tab:test-files
    #+ATTR_LATEX: :align |l|l|l|
   |----------------------+--------------------------------------------------------|
   | Test                 | Test Files                                             |
   |----------------------+--------------------------------------------------------|
   | Simple Function Call | ~test_purecap_<calling-convention>_cc_simple_call~     |
   | Stack Growth         | ~test_purecap_<calling-convention>_cc_stack_growth~    |
   | Stack Growth -O1     | ~test_purecap_<calling-convention>_cc_stack_growth_O1~ |
   | Sum Factorials       | ~test_purecap_<calling-convention>_cc_slow_factorial~  |
   | Sums -O1             | ~test_purecap_<calling-convention>_cc_sums_O1~         |
   |----------------------+--------------------------------------------------------|
   
   One more note, the number of instructions is always measured without the comments in the 
   assembly file and the assembler directives are also not included in the count. The
   instruction count is for the actual number of instructions.
   
*** Simple Function Call
    The first program contains one single function invocation:
    #+begin_src c -n
    int doSomething(int a) {
	return a;
    }

    int main(void) {
	int value = doSomething(100);
	return value;
    }
    #+end_src
    
    The function ~doSomething~ returns the argument it was passed. The ~main~ function will
    return the value from the ~doSomething~ call (which will be 100).
    The tests for this example are ~test_purecap_original_cc_simple_call~ and 
    ~test_purecap_uninit_cc_simple_call~. In the python test files an assertion is made
    that the result of the program is 100. Both tests pass, so the calling convention does
    not alter the semantics of the program.
    Table \ref{tab:simple-call} shows some interesting statistics about the number of instructions of 
    each calling convention and the performance (the median in microseconds).
    
    #+CAPTION: Results for the simple function call
    #+NAME: tab:simple-call
    #+ATTR_LATEX: :align |c|c|c|
    |--------------------+--------------+-------------|
    | Calling Convention | Instructions | Performance |
    |--------------------+--------------+-------------|
    | Original           |           39 |    942.2315 |
    | Secure             |           66 |    982.0340 |
    |--------------------+--------------+-------------|
    
    The performance is visualized using a box plot in Figure \ref{fig:simple-call}.
    #+CAPTION: Boxplot performance of the simple call program
    #+NAME: fig:simple-call
    #+ATTR_LATEX: :width 0.8\textwidth
    [[../../figures/boxplot-simple-call.png]]
    \FloatBarrier
    
    From this boxplot and the table above we can conclude that the new calling convention is slower
    than the original calling convention, which was expected, but not much slower, the overhead
    is acceptable. 
    
*** Stack Growth
    This program has a function that calls another function, requires spilling arguments
    to the stack and creates capabilities for variables.
    #+begin_src c -n
    int g(int *a, int *b) {
	return (*a) + (*b);
    }

    int f(int a) {
	int x = 10;
	return g(&a, &x);
    }

    int tmp(int a, int b, int c, int d, int e, int f, int g, int h, int i, int j) {
	return a + b + c + d + e + f + g + h + i + j;
    }

    int cap_tmp(int *a, int *b, int *c, int *d, int *e, int *f, int *g, int *h, int *i, int *j) {
	return (*a) + (*b) + (*c) + (*d) + (*e) + (*f) + (*g) + (*h) + (*i) + (*j);
    }

    int mixed_tmp(int a, int *b, int c, int *d, int e, int *f, int g, int *h, int i, int *j, int k, int *l) {
	return a + (*b) + c + (*d) + e + (*f) + g + (*h) + i + (*j);
    }

    int main(void) {
	int a = 1;
	int b = 2;
	int c = 3;
	int d = 4;
	int e = 5;
	int x = 6;
	int g = 7;
	int h = 8;
	int i = 9;
	int j = 10;
	tmp(a, b, c, d, e, x, g, h, i, j);
	cap_tmp(&a, &b, &c, &d, &e, &x, &g, &h, &i, &j);
	mixed_tmp(a, &b, c, &d, e, &x, g, &h, i, &j, i, &j);
	return f(10);
    }
    #+end_src

    The ~tmp~ and ~cap_tmp~ functions are interesting because they require
    argument spilling to the stack (remember that only 8 integers can be passed in general-purpose
    registers and 8 capabilities in capability registers). ~mixed_tmp~ does not require any argument
    spilling, it takes 12 parameters but half of them are integers and half capabilities, so these
    can be passed in registers (6 parameters using general-purpose registers and 6 using capability
    registers).
    The ~f~ function calls ~g~ with capabilities for its parameter ~a~ and a local variable ~x~.

    To test the semantics of this program, not only the value of the main function is considered,
    but the return values from the function calls to ~tmp~, ~cap_tmp~ and ~mixed_tmp~ are also
    tested to make sure their result remains the same in the original calling convention and the
    new calling convention. The tests pass for both calling conventions, thus the semantics of the
    program are preserved.

    Table \ref{tab:stack-growth} shows some interesting statistics about the number of instructions of 
    each calling convention and the performance (the median in microseconds).
    
    #+CAPTION: Results for the stack growth program
    #+NAME: tab:stack-growth
    #+ATTR_LATEX: :align |c|c|c|
    |--------------------+--------------+-------------|
    | Calling Convention | Instructions | Performance |
    |--------------------+--------------+-------------|
    | Original           |          393 |   1752.0225 |
    | Secure             |          647 |   2347.0310 |
    |--------------------+--------------+-------------|
    
    The performance is visualized using a box plot in Figure \ref{fig:stack-growth}.
    #+CAPTION: Boxplot performance of the stack growth program
    #+NAME: fig:stack-growth
    #+ATTR_LATEX: :width 0.8\textwidth
    [[../../figures/boxplot-stack-growth.png]]
    \FloatBarrier
    
    From the boxplot and Table \ref{tab:stack-growth} we learn that the program is slower
    when more function invocations take place. This makes sense because the calling convention
    poses an overhead for function calls, instruction sequences that do not perform a function
    invocation or don't return from a function, are only altered for storing contents on the stack,
    which should have similar performance to the existing store instructions (CS[BHWD], CSC).

*** Stack Growth -O1
    All the other programs used in the evaluation were compiled with optimization level 0, but
    the stack growth example has also been compiled with optimization level 1. The assembly generated
    by the compiler is used for the original test case and has also been modified to use the new 
    calling convention. 
    With this optimization level, the calls to the functions of which the return value is not used
    are omitted. Stack frames are also used better and are as small as possible. Redundant loads and
    stores have also been removed now.
    Table \ref{tab:stack-growth-O1} summarizes the results of evaluating the original calling convention
    and the secure calling convention for this program.

    #+CAPTION: Results for the stack growth program compiled with -O1
    #+NAME: tab:stack-growth-O1
    #+ATTR_LATEX: :align |c|c|c|
    |--------------------+--------------+-------------|
    | Calling Convention | Instructions | Performance |
    |--------------------+--------------+-------------|
    | Original           |           88 |    936.3010 |
    | Secure             |          196 |   1097.5060 |
    |--------------------+--------------+-------------|
    
    The performance is visualized using a box plot in Figure \ref{fig:stack-growth-O1}.
    #+CAPTION: Boxplot performance of the stack growth program compiled with -O1
    #+NAME: fig:stack-growth-O1
    #+ATTR_LATEX: :width 0.8\textwidth
    [[../../figures/boxplot-stack-growth-O1.png]]
    \FloatBarrier

    Even though the number of instructions doubled, the performance isn't that much
    affected. This is because some of the stack clearing instructions have been removed due
    to smaller stack frames of individual functions (smaller stack frames require less clearing
    before returning to the caller of the function).

*** Sum Factorials
    The program for this section calculates the sum of the first four factorials, i.e. $0! + 1! + 2! + 3!$.
    It uses an array to hold the factorials and after calculating the factorials of each number it
    adds them together. 
    #+begin_src c -n
    int product(int a, int b) {
	return a * b;
    }

    int factorial(int n) {
	int total = 1;

	for (int i = n; i > 1; i--) {
	    total = product(total, i);
	}

	return total;
    }

    int sum(int nums[], int length) {
	int sum = 0;

	for (int i = 0; i < length; i++) {
	    sum += nums[i]; 
	}

	return sum;
    }

    int sumFactorials() {
	int length = 4;
	int fact[4];
	fact[0] = 1;

	for (int i = 1; i < length; i++) {
	    fact[i] = factorial(i);
	}

	return sum(fact, length);
    }

    int main(void) {
	return sumFactorials();
    }
    #+end_src
    
    The ~product~ function is defined to have some more function calls. The code should be easy
    to follow.
    Just as in the other tests, for both calling convention the return value of the main function
    is tested to be 10. This semantics preserving tests passes for both calling conventions.
    Table \ref{tab:slow-factorial} shows the number of instructions in the assembly code and
    the execution time (performance column, in microseconds) for each calling convention.

    #+CAPTION: Results for the sum of factorials program
    #+NAME: tab:slow-factorial
    #+ATTR_LATEX: :align |c|c|c|
    |--------------------+--------------+-------------|
    | Calling Convention | Instructions | Performance |
    |--------------------+--------------+-------------|
    | Original           |          205 |   1977.5115 |
    | Secure             |          412 |   2802.7360 |
    |--------------------+--------------+-------------|
    
    The performance is visualized using a box plot in Figure \ref{fig:slow-factorial}.
    #+CAPTION: Boxplot performance of the sum of factorials program
    #+NAME: fig:slow-factorial
    #+ATTR_LATEX: :width 0.8\textwidth
    [[../../figures/boxplot-slow-factorial.png]]
    \FloatBarrier
    
    The results from this evaluation are similar to the previous ones. There number of instructions
    has doubled and the overhead introduced by the secure calling convention is visible
    in the execution time.

*** Sums -O1
    One more program is considered, also compiled with optimization level 1.
    #+begin_src c -n
    #define LENGTH 10

    void integers(int arr[], int length, int start) {
	for (int i = 0; i < length; i++) {
	    arr[i] = start + i;
	}
    }

    int sum(int *arr, int length) {
	int total = 0;

	for (int *p = arr; p < arr + length; p++) {
	    total += *p;
	}

	return total;
    }

    int backwards_sum(int *arr, int length) {
	int total = 0;

	for (int *p = arr + length - 1; p >= arr; p--) {
	    total += *p;
	}

	return total;
    }

    int subtract_sums() {
	int arr[LENGTH];
	integers(arr, LENGTH, 1);
	return sum(arr, LENGTH) - backwards_sum(arr, LENGTH);
    }

    int main() {
	return subtract_sums();
    }
    #+end_src
    
    This program will compute the sum of the elements in an array, once starting from the
    first element, in the function ~sum~, and once starting from the end of the array,
    in the function ~backwards_sum~. The return value of the ~main~ function is the result
    of calling ~subtract_sums~, which creates a local array on the stack, populates it with
    the integers starting from 1 and subtracts the sums of the two sum functions.
    Having a loop start from the end of the array and decrement the pointer in the array is
    quite interesting, it requires that the capability decrements the offset with the size
    of the elements stored in the array. Uninitialized capabilities however, do not allow
    decrementing the offset, this can only be achieved by storing on the address immediately
    below the cursor. This is where the /CDropUninit/ instruction comes in handy, after the
    array is allocated on the stack, the capability for that array will have its cursor
    equal to its base, i.e. it has been initialized (with zeroes). This means that the
    /CDropUninit/ instruction can be used to make the capability for the array drop the
    uninitialized permission and becoming a read, write-local local capability. Decrementing
    the offset is possible again and this program will run as intended.
    As in the other examples, tests are setup so that the result from the program using the original
    and secure calling convention is both zero (the result of ~subtract_sums~ should clearly be zero).
    The test passes for both calling conventions.
    Table \ref{tab:sums-O1} summarizes the results of evaluating the original calling convention
    and the secure calling convention for the sums program.

    #+CAPTION: Results for the sums program compiled with -O1
    #+NAME: tab:sums-O1
    #+ATTR_LATEX: :align |c|c|c|
    |--------------------+--------------+-------------|
    | Calling Convention | Instructions | Performance |
    |--------------------+--------------+-------------|
    | Original           |           87 |   1292.1815 |
    | Secure             |          250 |   1589.1595 |
    |--------------------+--------------+-------------|
    
    The performance is visualized using a box plot in Figure \ref{fig:stack-growth-O1}.
    #+CAPTION: Boxplot performance of the sums program compiled with -O1
    #+NAME: fig:sums-O1
    #+ATTR_LATEX: :width 0.8\textwidth
    [[../../figures/boxplot-sums-O1.png]]
    \FloatBarrier
    
    The number of instructions has more than doubled for this program but the performance
    overhead is acceptable, this is because compiling with some optimization can reduce the
    size of stack frames, which in turn requires less stack clearing when a function returns
    to its caller.

*** Conclusion
    The performance of the programs discussed is slower using the secure calling convention. This
    is an expected observation, the secure calling convention requires clearing registers and
    that a called function clears its own stack frame before returning to the caller.
    The number of instructions doubles when using the secure calling convention, this is
    due to
    - getting a unique seal for each function invocation;
    - setting up the stack and return capability for the function to call;
    - clearing registers before jumping to the function;
    - clearing the stack frame before returning to the caller;
    - clearing registers before returning to the caller.

    The overhead is still an improvement when compared to the calling convention using local
    capabilities as described in Section [[sec:lau-cc]], which required clearing the unused part
    of the stack (the calling convention with uninitialized capabilities only requires that a
    function clears its own used stack frame).
    Also keep in mind that most of the programs were compiled with no optimization, in the
    two programs that were compiled with optimization level one, the overhead is less because
    the stack frames were smaller, resulting in less stack clearing before a function returns
    to its caller.
    
    Furthermore, clearing the registers using the /CClearRegs/ instruction might be faster in
    future updates to CHERI-MIPS. Instead of actually writing zeros
    to general-purpose registers or the null capability to capability registers, a bit per register
    could be used to indicate if it is valid or not. This bit would be cleared when clearing a 
    register and set on subsequent writes \parencite[page~194]{watson2019capability}.
